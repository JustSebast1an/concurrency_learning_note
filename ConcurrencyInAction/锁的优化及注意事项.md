锁在高并发的环境下，激烈的锁竞争会导致程序的性能下降，所以需要讨论锁的性能问题以及注意事项，例如：避免死锁、减小锁粒度、锁分离等。
在多核时代，使用多线程可以明显地提高系统的性能。但事实上，使用多线程的方式会额外增加系统的开销。对于单任务或者单线程而言，其主要资源消耗都花在任务本身，它既不需要维护并行数据结构间的一致性状态，也不需要为线程的切换和调度花费时间。但对于多线程应用来说，它需要额外维护多线程环境的特有信息。
并行计算之所以能够提高系统的性能，并不是因为它少干活了，而是因为并行计算可以更合理地进行任务调度，充分利用各个CPU资源。
**合理的并发，才能将多核CPU的性能发挥到极致。**
# 1. 提高锁性能的建议
### 1.1 减小锁持有时间
    对于使用锁进行并发控制的程序，在锁竞争过程中，单个线程对锁的持有时间与系统性能有着直接的关系。所以程序开发应该尽可能地减少对某个锁的占有时间，以减少线程间互斥的可能。
    一个优化的解决方案是，只在必要时进行同步，这样就能明显减少线程持有锁的时间，提高系统的吞吐量。（这种手段比如对应着源码中处理正则表达式的Pattern类，只在表达式未编译时进行局部加锁）
    减少锁的持有时间有助于降低锁冲突的可能性，进而提升系统的并发能力。
### 1.2 减小锁粒度
    减小锁粒度的典型使用场景就是ConcurrentHashMap类的实现。对于ConcurrentHashMap，它内部进一步细分了若干个小的HashMap，称之为段。默认情况下，一个ConcurrentHashMap被进一步细分为16个段。如果需要在ConcurrentHashMap中增加一个新的表现，并不是将整个HashMap加锁，而是首先根据hashcode得到该表项应该被存放到哪个段中，然后对该段加锁，并完成put()操作。在多线程环境中，如果多个线程同时进行put()操作，只要被加入的表项不存放在同一个段中，则线程间便可以做到真正的并行。
```java
public V put(K key, V value) {
    Segment<K,V> s;
    if(value==null)
        throw new NullPointerException();
    int hash = hash(key);
    int j = (hash >>> segmentShift) & segmentMask;
    if ((s=(Segment<K,V>)UNSAFE.getObject(segments,(j<<SSHIFT)+SBASE))==null)
        s = ensureSegment(j);
    return s.put(key,hash,value,false);
}
```
    但是，减少锁粒度会引入新问题：当系统需要取得全局锁时，其消耗的资源会比较多。ConcurrentHashMap类put()方法很好地分离了锁，但是试图访问ConcurrentHashMap全局信息时，就会需要同时取得所有段的锁才能顺利实施。例如ConcurrentHashMap的size()方法：
```java
sum = 0;
//对所有的段加锁
for(int i=0; i<segments.length; i++)
    segments[i].lock();
//统计总数
for(int i=0; i<segments.length; ++i)
    sum += segments[i].count;
//释放所有的锁
for(int i=0; i<segments.length; ++i)
    segments[i].unlock();
```
    ！！！但是ConcurrentHashMap的size()方法并不总这样执行，size()方法会先使用无锁的方式求和，如果失败才会尝试加锁的方法，但是在高并发场合ConcurrentHashMap的size()性能依然差于同步的HashMap。
    所以，只有在获取全局信息的方法调用不频繁时，减小锁粒度的方法才能真正意义上提高系统吞吐量。
    减小锁粒度，就是指缩小锁定对象的范围，从而减少锁冲突的可能性，进而提高系统的并发能力。
### 1.3 读写分离锁替换独占锁
    读写分离锁来替代独占锁是减小锁粒度的一种特殊情况，减少锁粒度是通过分割数据结构实现的，而读写锁是对系统功能点的分割，例如读写锁ReadWriteLock。
    在读多写少的场合，使用读写锁可以有效提升系统的并发能力。
### 1.4 锁分离
    将读写锁思想进行延伸，就是锁分离。使用类似的分离思想，也可以对独占锁进行分离，典型就是java.util.concurrent.LinkedBlockingQueue的实现。take()和put()函数分别实现了从队列中取得数据和往队列中增加数据的功能，虽然都对队列进行了修改操作，但由于其基于链表的，两个操作分别作用于队列的前端和尾端，从理论上来说，两者并不冲突。
    所以在JDK的实现中，没有采用独占锁的方式，而是使用两把不同的锁，分离了take()和put()操作。通过takeLock和putLock两把锁，LinkedBlockingQueue实现了取数据和写数据的分离，使两者在真正意义上成为可并发的操作。
### 1.5 锁粗化
    为了保证多线程间的有效并发，会要求每个线程在使用完公共资源后，应该立即释放锁。但是，凡事都有一个度，如果对同一个锁不停地进行请求、同步和释放，其本身也会消耗系统资源，反而不利于性能的优化。
    所以，虚拟机在遇到一连串连续地对同一锁不断进行请求和释放的操作时，就会把所有的锁操作整合成对锁的一次请求，从而减少对锁的请求同步次数，这就叫做锁的粗化。
    在开发过程中，应该有意识地在合理的场合进行锁的粗化，尤其当在循环内请求锁时。
    性能优化就是根据运行时的真实情况对各个资源点进行权衡折中的过程。锁粗化的思想和减少锁持有的时间是相反的，但在不同的场合，它们的效果并不相同。所以需要根据实际情况，进行权衡。
# 2. Java虚拟机对锁优化的努力
### 2.1 锁偏向
    锁偏向是一种针对加锁操作的优化手段。其核心思想：如果一个线程获得了锁，那么锁就进入偏向模式。当这个线程再次请求锁时，无须再做任何同步操作，这就节省了大量有关锁申请的操作，从而提高了性能。
    对于几乎没有锁竞争的场合，偏向锁有比较好的优化效果，因为连续多次极有可能是同一个线程请求相同的锁。对于锁竞争比较激烈的场合，其效果不佳，偏向模式可能会失效。使用Java虚拟机参数-XX:+UseBiasedLocking可以开启偏向锁。
### 2.2 轻量级锁
    如果偏向锁失败，虚拟机不会立即挂起线程，它还会使用一种称为轻量级锁的优化手段。
    轻量级锁只是简单地将对象头部作为指针，指向持有锁的线程堆栈的内部，来判断一个线程是否持有对象锁。如果线程获得轻量级锁成功，则可以顺利进入临界区。如果轻量级锁加锁失败，则表示其他线程抢先争夺到了锁，那么当前线程的锁请求就会膨胀为重量级锁。
### 2.3 自旋锁
    锁膨胀后，虚拟机为了避免线程真实地在操作系统层面挂起，虚拟机还会尝试自旋锁。
    系统会进行一次赌注：假设在不久的将来，线程可以得到这把锁。所以虚拟机会让当前线程做几个空循环，就是自旋的含义，在经过若干次循环后，如果可以得到锁就顺利进入临界区。如果不能获得锁，才会真实地将线程在操作系统层面挂起。
### 2.4 锁消除
    Java虚拟机在JIT编译时，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁。通过锁消除，可以节省无意义的请求锁时间。使用-XX:+EliminateLocks参数可以打开锁消除。
# 3. ThreadLocal
### 3.1 ThreadLocal的简单使用
    这是一个线程的局部变量，也就是说，只有当前线程可以访问，所以自然是线程安全的。
    为每一个线程人手分配一个对象的工作并不是由ThreadLocal来完成的，而是需要在应用层面保证的。如果在应用上为每一个线程分配了相同的对象实例，那么ThreadLocal也不能保证线程安全。
    ！！！为每一个线程分配不同的对象需要在应用层面保证，ThreadLocal只是起到了简单的容器作用。
### 3.2 实现原理
    ThreadLocal的set()方法：
```java
public void set(T value) {
    Thread t = Thread.currentThread();
    ThreadLockMap map = getMap(t);
    if (map != null)
        map.set(this,value);
    else
        createMap(t,value);
}
```
    设置到ThreadLocal中的数据，正是写入了threadLocals这个Map。其中，key为ThreadLocal当前对象，value就是我们需要的值。而threadLocals本身就保存了当前自己所在线程的所有“局部变量”，也就是一个ThreadLocal变量的集合。
    get()方法就似乎先取得当前线程的ThreadLocalMap对象，然后通过将自己作为key取得内部的实际数据：
```java
public T get(){
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if(map!=null){
        ThreadLocalMap.Entry e = map.getEntry(this);
        if(e!=null)
            return (T)e.value;
    }
    return setInitialValue();
}
```
    这些变量是维护在Thread类内部的，意味着只要线程不退出，对象的引用将一直存在。如果使用线程池，就意味着当前线程未必会退出。若果将大对象设置到ThreadLocal中，可能会使系统出现内存泄漏的可能。
    ThreadLocalMap的实现使用了弱引用。Java虚拟机在垃圾回收时，如果发现弱引用，就会立即回收。
# 4. 无锁
对于并发控制而言，锁是悲观的策略。而无锁是一种乐观的策略，它会假设对资源的访问是没有冲突的。无锁的策略使用叫做比较交换的技术CAS来鉴别线程冲突，一旦检测到冲突产生，就重试当前操作直到没有冲突为止。
### 4.1 比较交换CAS
    与锁相比，使用CAS会使程序看起来更加复杂一些，但是它有非阻塞性以及线程间的相互影响也更小。而且使用无锁的方式完全没有锁竞争带来的系统开销，也没有线程间频繁调度带来的开销，所以比基于锁的方式拥有更优越的性能。
    CAS算法：包含三个参数V,E,N。V表示要更新的变量，E表示预期值，N表示新值。仅当V值等于E值时，才会将V的值设为N，如果V值和E值不同，则说明已经有其他线程做了更新，则当前线程什么都不做。最后，CAS返回当前V的真实值。
    CAS操作总是认为自己可以成功完成操作。当多个线程同时使用CAS操作一个变量时，只有一个会胜出并成功更新，其余均会失败。失败的线程不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作。所以，CAS操作即使没有锁，也可以发现其他线程对当前线程的干扰，并进行恰当的处理。
### 4.2 AtomicInteger:无锁的线程安全整数
    为了能够受益于CAS等CPU指令，JDK并发包中有一个atomic包，里面实现了一些直接使用CAS操作的线程安全的类型。
    AtomicInteger类是可变的，并且是线程安全的。对其进行修改等任何操作，都是用CAS指令进行的。AtomicInteger中保存着一个核心字段：
```java
private volatile int value;
private static final long valueOffset;
```
    value就代表了AtomicInteger的当前实际取值，valueOffset保存着value字段在AtomicInteger对象中的偏移量，这是实现AtomicInteger的关键。
    AtomicInteger的一些主要方法，对其他原子类，操作也是类似的：
```java
//取得当前值
public final int get()
//设置当前值
public final void set(int newValue)
//设置新值，并返回旧值
public final int getAndSet(int newValue)
//如果当前值为expect，则设置为u
public final boolean compareAndSet(int expect, int u)
//类似于i++
public final int getAndIncrement()
//i--
public final int getAndDecrement()
//当前值加delta，返回旧值
public final int getAndAdd(int delta)
// ++i
public final int incrementAndGet()
public final int decrementAndGet()
//当前值增加delta，返回新值
public final int addAndGet(int delta)
```

# 5. 死锁问题
死锁就是两个或者多个线程，相互占用对方需要的资源，而都不进行释放，导致彼此之间都相互等待对方释放资源，产生了无限制等待的现象。
如果需要确认死锁问题，需要使用JDK提高的专业工具。首先，可以使用jps命令得到java进行的进程ID，接着使用jstack命令得到线程的线程堆栈。
如果想避免死锁，除了使用无锁的函数外，还有就是使用重入锁，通过重入锁的中断或者限时等待可以有效规避死锁带来的问题。
